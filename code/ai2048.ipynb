{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPdz2S2vmBbjzOy/sPtVEsq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HEP-Dexan3327/AI-Diary-3-ReinforcementLearning/blob/main/code/ai2048.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://github.com/korakot/kora/releases/download/v0.10/py310.sh\n",
        "!bash ./py310.sh -b -f -p /usr/local\n",
        "!python -m ipykernel install --name \"py310\" --user"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tb-Md99O41Ii",
        "outputId": "576ab3f6-6d72-496d-9040-ea12662db0bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-01-10 12:07:34--  https://github.com/korakot/kora/releases/download/v0.10/py310.sh\n",
            "Resolving github.com (github.com)... 140.82.113.3\n",
            "Connecting to github.com (github.com)|140.82.113.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/266951884/0d0623be-3dec-4820-9e7b-69a3a5a75ef7?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20230110%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20230110T120734Z&X-Amz-Expires=300&X-Amz-Signature=4a4b70e2b52090e2eba41184764e19552482f1e37fa2c280023510ad98958aa2&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=266951884&response-content-disposition=attachment%3B%20filename%3Dpy310.sh&response-content-type=application%2Foctet-stream [following]\n",
            "--2023-01-10 12:07:34--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/266951884/0d0623be-3dec-4820-9e7b-69a3a5a75ef7?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20230110%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20230110T120734Z&X-Amz-Expires=300&X-Amz-Signature=4a4b70e2b52090e2eba41184764e19552482f1e37fa2c280023510ad98958aa2&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=266951884&response-content-disposition=attachment%3B%20filename%3Dpy310.sh&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.111.133, 185.199.108.133, 185.199.109.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 364632383 (348M) [application/octet-stream]\n",
            "Saving to: ‘py310.sh’\n",
            "\n",
            "py310.sh            100%[===================>] 347.74M   126MB/s    in 2.8s    \n",
            "\n",
            "2023-01-10 12:07:37 (126 MB/s) - ‘py310.sh’ saved [364632383/364632383]\n",
            "\n",
            "PREFIX=/usr/local\n",
            "Unpacking payload ...\n",
            "Collecting package metadata (current_repodata.json): - \b\b\\ \b\b| \b\bdone\n",
            "Solving environment: - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\bdone\n",
            "\n",
            "## Package Plan ##\n",
            "\n",
            "  environment location: /usr/local\n",
            "\n",
            "  added / updated specs:\n",
            "    - _libgcc_mutex==0.1=conda_forge\n",
            "    - _openmp_mutex==4.5=2_gnu\n",
            "    - aiohttp==3.8.3=py310h5764c6d_1\n",
            "    - aiosignal==1.2.0=pyhd8ed1ab_0\n",
            "    - alsa-lib==1.2.7.2=h166bdaf_0\n",
            "    - argon2-cffi-bindings==21.2.0=py310h5764c6d_3\n",
            "    - argon2-cffi==21.3.0=pyhd8ed1ab_0\n",
            "    - asttokens==2.0.8=pyhd8ed1ab_0\n",
            "    - async-timeout==4.0.2=pyhd8ed1ab_0\n",
            "    - attr==2.5.1=h166bdaf_1\n",
            "    - attrs==22.1.0=pyh71513ae_1\n",
            "    - backcall==0.2.0=pyh9f0ad1d_0\n",
            "    - backports.functools_lru_cache==1.6.4=pyhd8ed1ab_0\n",
            "    - backports==1.0=py_2\n",
            "    - beautifulsoup4==4.11.1=pyha770c72_0\n",
            "    - bleach==5.0.1=pyhd8ed1ab_0\n",
            "    - brotlipy==0.7.0=py310h5764c6d_1005\n",
            "    - bzip2==1.0.8=h7f98852_4\n",
            "    - ca-certificates==2022.9.24=ha878542_0\n",
            "    - cachetools==5.2.0=pyhd8ed1ab_0\n",
            "    - certifi==2022.9.24=pyhd8ed1ab_0\n",
            "    - cffi==1.15.1=py310h255011f_2\n",
            "    - charset-normalizer==2.1.1=pyhd8ed1ab_0\n",
            "    - colorama==0.4.6=pyhd8ed1ab_0\n",
            "    - conda-package-handling==1.9.0=py310h5764c6d_1\n",
            "    - conda==22.9.0=py310hff52083_1\n",
            "    - cryptography==38.0.2=py310h597c629_2\n",
            "    - dbus==1.13.6=h5008d03_3\n",
            "    - debugpy==1.6.3=py310hd8f1fbe_1\n",
            "    - decorator==5.1.1=pyhd8ed1ab_0\n",
            "    - defusedxml==0.7.1=pyhd8ed1ab_0\n",
            "    - entrypoints==0.4=pyhd8ed1ab_0\n",
            "    - executing==1.1.1=pyhd8ed1ab_0\n",
            "    - expat==2.5.0=h27087fc_0\n",
            "    - fftw==3.3.10=nompi_hf0379b8_105\n",
            "    - flit-core==3.7.1=pyhd8ed1ab_0\n",
            "    - font-ttf-dejavu-sans-mono==2.37=hab24e00_0\n",
            "    - font-ttf-inconsolata==3.000=h77eed37_0\n",
            "    - font-ttf-source-code-pro==2.038=h77eed37_0\n",
            "    - font-ttf-ubuntu==0.83=hab24e00_0\n",
            "    - fontconfig==2.14.1=hc2a2eb6_0\n",
            "    - fonts-conda-ecosystem==1=0\n",
            "    - fonts-conda-forge==1=0\n",
            "    - freetype==2.12.1=hca18f0e_0\n",
            "    - frozenlist==1.3.1=py310h5764c6d_1\n",
            "    - gettext==0.21.1=h27087fc_0\n",
            "    - glib-tools==2.74.1=h6239696_0\n",
            "    - glib==2.74.1=h6239696_0\n",
            "    - google-auth==2.13.0=pyh1a96a4e_0\n",
            "    - google-colab==1.0.0=pyh44b312d_0\n",
            "    - gst-plugins-base==1.20.3=h57caac4_2\n",
            "    - gstreamer==1.20.3=hd4edc92_2\n",
            "    - icu==70.1=h27087fc_0\n",
            "    - idna==3.4=pyhd8ed1ab_0\n",
            "    - importlib-metadata==5.0.0=pyha770c72_1\n",
            "    - importlib_resources==5.10.0=pyhd8ed1ab_0\n",
            "    - ipykernel==6.16.2=pyh210e3f2_0\n",
            "    - ipython==8.5.0=pyh41d4057_1\n",
            "    - ipython_genutils==0.2.0=py_1\n",
            "    - ipywidgets==8.0.2=pyhd8ed1ab_1\n",
            "    - jack==1.9.21=h2a1e645_0\n",
            "    - jedi==0.18.1=pyhd8ed1ab_2\n",
            "    - jinja2==3.1.2=pyhd8ed1ab_1\n",
            "    - jpeg==9e=h166bdaf_2\n",
            "    - jsonschema==4.16.0=pyhd8ed1ab_0\n",
            "    - jupyter==1.0.0=py310hff52083_7\n",
            "    - jupyter_client==7.4.4=pyhd8ed1ab_0\n",
            "    - jupyter_console==6.4.4=pyhd8ed1ab_0\n",
            "    - jupyter_core==4.11.1=py310hff52083_1\n",
            "    - jupyterlab_pygments==0.2.2=pyhd8ed1ab_0\n",
            "    - jupyterlab_widgets==3.0.3=pyhd8ed1ab_0\n",
            "    - keyutils==1.6.1=h166bdaf_0\n",
            "    - krb5==1.19.3=h3790be6_0\n",
            "    - lame==3.100=h166bdaf_1003\n",
            "    - ld_impl_linux-64==2.39=hc81fddc_0\n",
            "    - libblas==3.9.0=16_linux64_openblas\n",
            "    - libcap==2.66=ha37c62d_0\n",
            "    - libcblas==3.9.0=16_linux64_openblas\n",
            "    - libclang13==14.0.6=default_h3a83d3e_0\n",
            "    - libclang==14.0.6=default_h2e3cab8_0\n",
            "    - libcups==2.3.3=h3e49a29_2\n",
            "    - libdb==6.2.32=h9c3ff4c_0\n",
            "    - libedit==3.1.20191231=he28a2e2_2\n",
            "    - libevent==2.1.10=h9b69904_4\n",
            "    - libffi==3.4.2=h7f98852_5\n",
            "    - libflac==1.4.2=h27087fc_0\n",
            "    - libgcc-ng==12.2.0=h65d4601_19\n",
            "    - libgfortran-ng==12.2.0=h69a702a_19\n",
            "    - libgfortran5==12.2.0=h337968e_19\n",
            "    - libglib==2.74.1=h7a41b64_0\n",
            "    - libgomp==12.2.0=h65d4601_19\n",
            "    - libiconv==1.17=h166bdaf_0\n",
            "    - liblapack==3.9.0=16_linux64_openblas\n",
            "    - libllvm14==14.0.6=he0ac6c6_0\n",
            "    - libnsl==2.0.0=h7f98852_0\n",
            "    - libogg==1.3.4=h7f98852_1\n",
            "    - libopenblas==0.3.21=pthreads_h78a6416_3\n",
            "    - libopus==1.3.1=h7f98852_1\n",
            "    - libpng==1.6.38=h753d276_0\n",
            "    - libpq==14.5=hd77ab85_1\n",
            "    - libsndfile==1.1.0=h27087fc_0\n",
            "    - libsodium==1.0.18=h36c2ea0_1\n",
            "    - libsqlite==3.39.4=h753d276_0\n",
            "    - libstdcxx-ng==12.2.0=h46fd767_19\n",
            "    - libtool==2.4.6=h9c3ff4c_1008\n",
            "    - libudev1==251=h166bdaf_0\n",
            "    - libuuid==2.32.1=h7f98852_1000\n",
            "    - libvorbis==1.3.7=h9c3ff4c_0\n",
            "    - libxcb==1.13=h7f98852_1004\n",
            "    - libxkbcommon==1.0.3=he3ba5ed_0\n",
            "    - libxml2==2.10.3=h7463322_0\n",
            "    - libzlib==1.2.13=h166bdaf_4\n",
            "    - markupsafe==2.1.1=py310h5764c6d_2\n",
            "    - matplotlib-inline==0.1.6=pyhd8ed1ab_0\n",
            "    - mistune==2.0.4=pyhd8ed1ab_0\n",
            "    - mpg123==1.30.2=h27087fc_1\n",
            "    - multidict==6.0.2=py310h5764c6d_2\n",
            "    - mysql-common==8.0.31=haf5c9bc_0\n",
            "    - mysql-libs==8.0.31=h28c427c_0\n",
            "    - nbclient==0.7.0=pyhd8ed1ab_0\n",
            "    - nbconvert-core==7.2.3=pyhd8ed1ab_0\n",
            "    - nbconvert-pandoc==7.2.3=pyhd8ed1ab_0\n",
            "    - nbconvert==7.2.3=pyhd8ed1ab_0\n",
            "    - nbformat==5.7.0=pyhd8ed1ab_0\n",
            "    - ncurses==6.3=h27087fc_1\n",
            "    - nest-asyncio==1.5.6=pyhd8ed1ab_0\n",
            "    - notebook==6.4.12=pyha770c72_0\n",
            "    - nspr==4.32=h9c3ff4c_1\n",
            "    - nss==3.78=h2350873_0\n",
            "    - numpy==1.23.4=py310h53a5b5f_1\n",
            "    - openssl==1.1.1q=h166bdaf_1\n",
            "    - packaging==21.3=pyhd8ed1ab_0\n",
            "    - pandas==1.5.1=py310h769672d_1\n",
            "    - pandoc==2.19.2=h32600fe_1\n",
            "    - pandocfilters==1.5.0=pyhd8ed1ab_0\n",
            "    - parso==0.8.3=pyhd8ed1ab_0\n",
            "    - pcre2==10.37=hc3806b6_1\n",
            "    - pexpect==4.8.0=pyh9f0ad1d_2\n",
            "    - pickleshare==0.7.5=py_1003\n",
            "    - pip==22.3=pyhd8ed1ab_0\n",
            "    - pkgutil-resolve-name==1.3.10=pyhd8ed1ab_0\n",
            "    - ply==3.11=py_1\n",
            "    - portpicker==1.5.2=pyhd8ed1ab_0\n",
            "    - prometheus_client==0.15.0=pyhd8ed1ab_0\n",
            "    - prompt-toolkit==3.0.31=pyha770c72_0\n",
            "    - prompt_toolkit==3.0.31=hd8ed1ab_0\n",
            "    - psutil==5.9.3=py310h5764c6d_1\n",
            "    - pthread-stubs==0.4=h36c2ea0_1001\n",
            "    - ptyprocess==0.7.0=pyhd3deb0d_0\n",
            "    - pulseaudio==14.0=habe0971_10\n",
            "    - pure_eval==0.2.2=pyhd8ed1ab_0\n",
            "    - pyasn1-modules==0.2.7=py_0\n",
            "    - pyasn1==0.4.8=py_0\n",
            "    - pycosat==0.6.4=py310h5764c6d_1\n",
            "    - pycparser==2.21=pyhd8ed1ab_0\n",
            "    - pygments==2.13.0=pyhd8ed1ab_0\n",
            "    - pyopenssl==22.1.0=pyhd8ed1ab_0\n",
            "    - pyparsing==3.0.9=pyhd8ed1ab_0\n",
            "    - pyqt5-sip==12.11.0=py310hd8f1fbe_2\n",
            "    - pyqt==5.15.7=py310h29803b5_2\n",
            "    - pyrsistent==0.18.1=py310h5764c6d_2\n",
            "    - pysocks==1.7.1=pyha2e5f31_6\n",
            "    - python-dateutil==2.8.2=pyhd8ed1ab_0\n",
            "    - python-fastjsonschema==2.16.2=pyhd8ed1ab_0\n",
            "    - python==3.10.6=h582c2e5_0_cpython\n",
            "    - python_abi==3.10=2_cp310\n",
            "    - pytz==2022.5=pyhd8ed1ab_0\n",
            "    - pyu2f==0.1.5=pyhd8ed1ab_0\n",
            "    - pyzmq==24.0.1=py310h330234f_1\n",
            "    - qt-main==5.15.6=hc525480_0\n",
            "    - qtconsole-base==5.3.2=pyha770c72_0\n",
            "    - qtconsole==5.3.2=pyhd8ed1ab_0\n",
            "    - qtpy==2.2.1=pyhd8ed1ab_0\n",
            "    - readline==8.1.2=h0f457ee_0\n",
            "    - requests==2.28.1=pyhd8ed1ab_1\n",
            "    - rsa==4.9=pyhd8ed1ab_0\n",
            "    - ruamel_yaml==0.15.80=py310h5764c6d_1008\n",
            "    - send2trash==1.8.0=pyhd8ed1ab_0\n",
            "    - setuptools==65.5.0=pyhd8ed1ab_0\n",
            "    - sip==6.7.2=py310hd8f1fbe_1\n",
            "    - six==1.16.0=pyh6c4a22f_0\n",
            "    - soupsieve==2.3.2.post1=pyhd8ed1ab_0\n",
            "    - sqlite==3.39.4=h4ff8645_0\n",
            "    - stack_data==0.5.1=pyhd8ed1ab_0\n",
            "    - terminado==0.17.0=pyh41d4057_0\n",
            "    - tinycss2==1.2.1=pyhd8ed1ab_0\n",
            "    - tk==8.6.12=h27826a3_0\n",
            "    - toml==0.10.2=pyhd8ed1ab_0\n",
            "    - toolz==0.12.0=pyhd8ed1ab_0\n",
            "    - tornado==6.2=py310h5764c6d_1\n",
            "    - tqdm==4.64.1=pyhd8ed1ab_0\n",
            "    - traitlets==5.5.0=pyhd8ed1ab_0\n",
            "    - typing-extensions==4.4.0=hd8ed1ab_0\n",
            "    - typing_extensions==4.4.0=pyha770c72_0\n",
            "    - tzdata==2022e=h191b570_0\n",
            "    - urllib3==1.26.11=pyhd8ed1ab_0\n",
            "    - wcwidth==0.2.5=pyh9f0ad1d_2\n",
            "    - webencodings==0.5.1=py_1\n",
            "    - wheel==0.37.1=pyhd8ed1ab_0\n",
            "    - widgetsnbextension==4.0.3=pyhd8ed1ab_0\n",
            "    - xcb-util-image==0.4.0=h166bdaf_0\n",
            "    - xcb-util-keysyms==0.4.0=h166bdaf_0\n",
            "    - xcb-util-renderutil==0.3.9=h166bdaf_0\n",
            "    - xcb-util-wm==0.4.1=h166bdaf_0\n",
            "    - xcb-util==0.4.0=h166bdaf_0\n",
            "    - xorg-libxau==1.0.9=h7f98852_0\n",
            "    - xorg-libxdmcp==1.1.3=h7f98852_0\n",
            "    - xz==5.2.6=h166bdaf_0\n",
            "    - yaml==0.2.5=h7f98852_2\n",
            "    - yarl==1.8.1=py310h5764c6d_0\n",
            "    - zeromq==4.3.4=h9c3ff4c_1\n",
            "    - zipp==3.10.0=pyhd8ed1ab_0\n",
            "    - zstd==1.5.2=h6239696_4\n",
            "\n",
            "\n",
            "The following NEW packages will be INSTALLED:\n",
            "\n",
            "  _libgcc_mutex      conda-forge/linux-64::_libgcc_mutex-0.1-conda_forge\n",
            "  _openmp_mutex      conda-forge/linux-64::_openmp_mutex-4.5-2_gnu\n",
            "  aiohttp            conda-forge/linux-64::aiohttp-3.8.3-py310h5764c6d_1\n",
            "  aiosignal          conda-forge/noarch::aiosignal-1.2.0-pyhd8ed1ab_0\n",
            "  alsa-lib           conda-forge/linux-64::alsa-lib-1.2.7.2-h166bdaf_0\n",
            "  argon2-cffi        conda-forge/noarch::argon2-cffi-21.3.0-pyhd8ed1ab_0\n",
            "  argon2-cffi-bindi~ conda-forge/linux-64::argon2-cffi-bindings-21.2.0-py310h5764c6d_3\n",
            "  asttokens          conda-forge/noarch::asttokens-2.0.8-pyhd8ed1ab_0\n",
            "  async-timeout      conda-forge/noarch::async-timeout-4.0.2-pyhd8ed1ab_0\n",
            "  attr               conda-forge/linux-64::attr-2.5.1-h166bdaf_1\n",
            "  attrs              conda-forge/noarch::attrs-22.1.0-pyh71513ae_1\n",
            "  backcall           conda-forge/noarch::backcall-0.2.0-pyh9f0ad1d_0\n",
            "  backports          conda-forge/noarch::backports-1.0-py_2\n",
            "  backports.functoo~ conda-forge/noarch::backports.functools_lru_cache-1.6.4-pyhd8ed1ab_0\n",
            "  beautifulsoup4     conda-forge/noarch::beautifulsoup4-4.11.1-pyha770c72_0\n",
            "  bleach             conda-forge/noarch::bleach-5.0.1-pyhd8ed1ab_0\n",
            "  brotlipy           conda-forge/linux-64::brotlipy-0.7.0-py310h5764c6d_1005\n",
            "  bzip2              conda-forge/linux-64::bzip2-1.0.8-h7f98852_4\n",
            "  ca-certificates    conda-forge/linux-64::ca-certificates-2022.9.24-ha878542_0\n",
            "  cachetools         conda-forge/noarch::cachetools-5.2.0-pyhd8ed1ab_0\n",
            "  certifi            conda-forge/noarch::certifi-2022.9.24-pyhd8ed1ab_0\n",
            "  cffi               conda-forge/linux-64::cffi-1.15.1-py310h255011f_2\n",
            "  charset-normalizer conda-forge/noarch::charset-normalizer-2.1.1-pyhd8ed1ab_0\n",
            "  colorama           conda-forge/noarch::colorama-0.4.6-pyhd8ed1ab_0\n",
            "  conda              conda-forge/linux-64::conda-22.9.0-py310hff52083_1\n",
            "  conda-package-han~ conda-forge/linux-64::conda-package-handling-1.9.0-py310h5764c6d_1\n",
            "  cryptography       conda-forge/linux-64::cryptography-38.0.2-py310h597c629_2\n",
            "  dbus               conda-forge/linux-64::dbus-1.13.6-h5008d03_3\n",
            "  debugpy            conda-forge/linux-64::debugpy-1.6.3-py310hd8f1fbe_1\n",
            "  decorator          conda-forge/noarch::decorator-5.1.1-pyhd8ed1ab_0\n",
            "  defusedxml         conda-forge/noarch::defusedxml-0.7.1-pyhd8ed1ab_0\n",
            "  entrypoints        conda-forge/noarch::entrypoints-0.4-pyhd8ed1ab_0\n",
            "  executing          conda-forge/noarch::executing-1.1.1-pyhd8ed1ab_0\n",
            "  expat              conda-forge/linux-64::expat-2.5.0-h27087fc_0\n",
            "  fftw               conda-forge/linux-64::fftw-3.3.10-nompi_hf0379b8_105\n",
            "  flit-core          conda-forge/noarch::flit-core-3.7.1-pyhd8ed1ab_0\n",
            "  font-ttf-dejavu-s~ conda-forge/noarch::font-ttf-dejavu-sans-mono-2.37-hab24e00_0\n",
            "  font-ttf-inconsol~ conda-forge/noarch::font-ttf-inconsolata-3.000-h77eed37_0\n",
            "  font-ttf-source-c~ conda-forge/noarch::font-ttf-source-code-pro-2.038-h77eed37_0\n",
            "  font-ttf-ubuntu    conda-forge/noarch::font-ttf-ubuntu-0.83-hab24e00_0\n",
            "  fontconfig         conda-forge/linux-64::fontconfig-2.14.1-hc2a2eb6_0\n",
            "  fonts-conda-ecosy~ conda-forge/noarch::fonts-conda-ecosystem-1-0\n",
            "  fonts-conda-forge  conda-forge/noarch::fonts-conda-forge-1-0\n",
            "  freetype           conda-forge/linux-64::freetype-2.12.1-hca18f0e_0\n",
            "  frozenlist         conda-forge/linux-64::frozenlist-1.3.1-py310h5764c6d_1\n",
            "  gettext            conda-forge/linux-64::gettext-0.21.1-h27087fc_0\n",
            "  glib               conda-forge/linux-64::glib-2.74.1-h6239696_0\n",
            "  glib-tools         conda-forge/linux-64::glib-tools-2.74.1-h6239696_0\n",
            "  google-auth        conda-forge/noarch::google-auth-2.13.0-pyh1a96a4e_0\n",
            "  google-colab       conda-forge/noarch::google-colab-1.0.0-pyh44b312d_0\n",
            "  gst-plugins-base   conda-forge/linux-64::gst-plugins-base-1.20.3-h57caac4_2\n",
            "  gstreamer          conda-forge/linux-64::gstreamer-1.20.3-hd4edc92_2\n",
            "  icu                conda-forge/linux-64::icu-70.1-h27087fc_0\n",
            "  idna               conda-forge/noarch::idna-3.4-pyhd8ed1ab_0\n",
            "  importlib-metadata conda-forge/noarch::importlib-metadata-5.0.0-pyha770c72_1\n",
            "  importlib_resourc~ conda-forge/noarch::importlib_resources-5.10.0-pyhd8ed1ab_0\n",
            "  ipykernel          conda-forge/noarch::ipykernel-6.16.2-pyh210e3f2_0\n",
            "  ipython            conda-forge/noarch::ipython-8.5.0-pyh41d4057_1\n",
            "  ipython_genutils   conda-forge/noarch::ipython_genutils-0.2.0-py_1\n",
            "  ipywidgets         conda-forge/noarch::ipywidgets-8.0.2-pyhd8ed1ab_1\n",
            "  jack               conda-forge/linux-64::jack-1.9.21-h2a1e645_0\n",
            "  jedi               conda-forge/noarch::jedi-0.18.1-pyhd8ed1ab_2\n",
            "  jinja2             conda-forge/noarch::jinja2-3.1.2-pyhd8ed1ab_1\n",
            "  jpeg               conda-forge/linux-64::jpeg-9e-h166bdaf_2\n",
            "  jsonschema         conda-forge/noarch::jsonschema-4.16.0-pyhd8ed1ab_0\n",
            "  jupyter            conda-forge/linux-64::jupyter-1.0.0-py310hff52083_7\n",
            "  jupyter_client     conda-forge/noarch::jupyter_client-7.4.4-pyhd8ed1ab_0\n",
            "  jupyter_console    conda-forge/noarch::jupyter_console-6.4.4-pyhd8ed1ab_0\n",
            "  jupyter_core       conda-forge/linux-64::jupyter_core-4.11.1-py310hff52083_1\n",
            "  jupyterlab_pygmen~ conda-forge/noarch::jupyterlab_pygments-0.2.2-pyhd8ed1ab_0\n",
            "  jupyterlab_widgets conda-forge/noarch::jupyterlab_widgets-3.0.3-pyhd8ed1ab_0\n",
            "  keyutils           conda-forge/linux-64::keyutils-1.6.1-h166bdaf_0\n",
            "  krb5               conda-forge/linux-64::krb5-1.19.3-h3790be6_0\n",
            "  lame               conda-forge/linux-64::lame-3.100-h166bdaf_1003\n",
            "  ld_impl_linux-64   conda-forge/linux-64::ld_impl_linux-64-2.39-hc81fddc_0\n",
            "  libblas            conda-forge/linux-64::libblas-3.9.0-16_linux64_openblas\n",
            "  libcap             conda-forge/linux-64::libcap-2.66-ha37c62d_0\n",
            "  libcblas           conda-forge/linux-64::libcblas-3.9.0-16_linux64_openblas\n",
            "  libclang           conda-forge/linux-64::libclang-14.0.6-default_h2e3cab8_0\n",
            "  libclang13         conda-forge/linux-64::libclang13-14.0.6-default_h3a83d3e_0\n",
            "  libcups            conda-forge/linux-64::libcups-2.3.3-h3e49a29_2\n",
            "  libdb              conda-forge/linux-64::libdb-6.2.32-h9c3ff4c_0\n",
            "  libedit            conda-forge/linux-64::libedit-3.1.20191231-he28a2e2_2\n",
            "  libevent           conda-forge/linux-64::libevent-2.1.10-h9b69904_4\n",
            "  libffi             conda-forge/linux-64::libffi-3.4.2-h7f98852_5\n",
            "  libflac            conda-forge/linux-64::libflac-1.4.2-h27087fc_0\n",
            "  libgcc-ng          conda-forge/linux-64::libgcc-ng-12.2.0-h65d4601_19\n",
            "  libgfortran-ng     conda-forge/linux-64::libgfortran-ng-12.2.0-h69a702a_19\n",
            "  libgfortran5       conda-forge/linux-64::libgfortran5-12.2.0-h337968e_19\n",
            "  libglib            conda-forge/linux-64::libglib-2.74.1-h7a41b64_0\n",
            "  libgomp            conda-forge/linux-64::libgomp-12.2.0-h65d4601_19\n",
            "  libiconv           conda-forge/linux-64::libiconv-1.17-h166bdaf_0\n",
            "  liblapack          conda-forge/linux-64::liblapack-3.9.0-16_linux64_openblas\n",
            "  libllvm14          conda-forge/linux-64::libllvm14-14.0.6-he0ac6c6_0\n",
            "  libnsl             conda-forge/linux-64::libnsl-2.0.0-h7f98852_0\n",
            "  libogg             conda-forge/linux-64::libogg-1.3.4-h7f98852_1\n",
            "  libopenblas        conda-forge/linux-64::libopenblas-0.3.21-pthreads_h78a6416_3\n",
            "  libopus            conda-forge/linux-64::libopus-1.3.1-h7f98852_1\n",
            "  libpng             conda-forge/linux-64::libpng-1.6.38-h753d276_0\n",
            "  libpq              conda-forge/linux-64::libpq-14.5-hd77ab85_1\n",
            "  libsndfile         conda-forge/linux-64::libsndfile-1.1.0-h27087fc_0\n",
            "  libsodium          conda-forge/linux-64::libsodium-1.0.18-h36c2ea0_1\n",
            "  libsqlite          conda-forge/linux-64::libsqlite-3.39.4-h753d276_0\n",
            "  libstdcxx-ng       conda-forge/linux-64::libstdcxx-ng-12.2.0-h46fd767_19\n",
            "  libtool            conda-forge/linux-64::libtool-2.4.6-h9c3ff4c_1008\n",
            "  libudev1           conda-forge/linux-64::libudev1-251-h166bdaf_0\n",
            "  libuuid            conda-forge/linux-64::libuuid-2.32.1-h7f98852_1000\n",
            "  libvorbis          conda-forge/linux-64::libvorbis-1.3.7-h9c3ff4c_0\n",
            "  libxcb             conda-forge/linux-64::libxcb-1.13-h7f98852_1004\n",
            "  libxkbcommon       conda-forge/linux-64::libxkbcommon-1.0.3-he3ba5ed_0\n",
            "  libxml2            conda-forge/linux-64::libxml2-2.10.3-h7463322_0\n",
            "  libzlib            conda-forge/linux-64::libzlib-1.2.13-h166bdaf_4\n",
            "  markupsafe         conda-forge/linux-64::markupsafe-2.1.1-py310h5764c6d_2\n",
            "  matplotlib-inline  conda-forge/noarch::matplotlib-inline-0.1.6-pyhd8ed1ab_0\n",
            "  mistune            conda-forge/noarch::mistune-2.0.4-pyhd8ed1ab_0\n",
            "  mpg123             conda-forge/linux-64::mpg123-1.30.2-h27087fc_1\n",
            "  multidict          conda-forge/linux-64::multidict-6.0.2-py310h5764c6d_2\n",
            "  mysql-common       conda-forge/linux-64::mysql-common-8.0.31-haf5c9bc_0\n",
            "  mysql-libs         conda-forge/linux-64::mysql-libs-8.0.31-h28c427c_0\n",
            "  nbclient           conda-forge/noarch::nbclient-0.7.0-pyhd8ed1ab_0\n",
            "  nbconvert          conda-forge/noarch::nbconvert-7.2.3-pyhd8ed1ab_0\n",
            "  nbconvert-core     conda-forge/noarch::nbconvert-core-7.2.3-pyhd8ed1ab_0\n",
            "  nbconvert-pandoc   conda-forge/noarch::nbconvert-pandoc-7.2.3-pyhd8ed1ab_0\n",
            "  nbformat           conda-forge/noarch::nbformat-5.7.0-pyhd8ed1ab_0\n",
            "  ncurses            conda-forge/linux-64::ncurses-6.3-h27087fc_1\n",
            "  nest-asyncio       conda-forge/noarch::nest-asyncio-1.5.6-pyhd8ed1ab_0\n",
            "  notebook           conda-forge/noarch::notebook-6.4.12-pyha770c72_0\n",
            "  nspr               conda-forge/linux-64::nspr-4.32-h9c3ff4c_1\n",
            "  nss                conda-forge/linux-64::nss-3.78-h2350873_0\n",
            "  numpy              conda-forge/linux-64::numpy-1.23.4-py310h53a5b5f_1\n",
            "  openssl            conda-forge/linux-64::openssl-1.1.1q-h166bdaf_1\n",
            "  packaging          conda-forge/noarch::packaging-21.3-pyhd8ed1ab_0\n",
            "  pandas             conda-forge/linux-64::pandas-1.5.1-py310h769672d_1\n",
            "  pandoc             conda-forge/linux-64::pandoc-2.19.2-h32600fe_1\n",
            "  pandocfilters      conda-forge/noarch::pandocfilters-1.5.0-pyhd8ed1ab_0\n",
            "  parso              conda-forge/noarch::parso-0.8.3-pyhd8ed1ab_0\n",
            "  pcre2              conda-forge/linux-64::pcre2-10.37-hc3806b6_1\n",
            "  pexpect            conda-forge/noarch::pexpect-4.8.0-pyh9f0ad1d_2\n",
            "  pickleshare        conda-forge/noarch::pickleshare-0.7.5-py_1003\n",
            "  pip                conda-forge/noarch::pip-22.3-pyhd8ed1ab_0\n",
            "  pkgutil-resolve-n~ conda-forge/noarch::pkgutil-resolve-name-1.3.10-pyhd8ed1ab_0\n",
            "  ply                conda-forge/noarch::ply-3.11-py_1\n",
            "  portpicker         conda-forge/noarch::portpicker-1.5.2-pyhd8ed1ab_0\n",
            "  prometheus_client  conda-forge/noarch::prometheus_client-0.15.0-pyhd8ed1ab_0\n",
            "  prompt-toolkit     conda-forge/noarch::prompt-toolkit-3.0.31-pyha770c72_0\n",
            "  prompt_toolkit     conda-forge/noarch::prompt_toolkit-3.0.31-hd8ed1ab_0\n",
            "  psutil             conda-forge/linux-64::psutil-5.9.3-py310h5764c6d_1\n",
            "  pthread-stubs      conda-forge/linux-64::pthread-stubs-0.4-h36c2ea0_1001\n",
            "  ptyprocess         conda-forge/noarch::ptyprocess-0.7.0-pyhd3deb0d_0\n",
            "  pulseaudio         conda-forge/linux-64::pulseaudio-14.0-habe0971_10\n",
            "  pure_eval          conda-forge/noarch::pure_eval-0.2.2-pyhd8ed1ab_0\n",
            "  pyasn1             conda-forge/noarch::pyasn1-0.4.8-py_0\n",
            "  pyasn1-modules     conda-forge/noarch::pyasn1-modules-0.2.7-py_0\n",
            "  pycosat            conda-forge/linux-64::pycosat-0.6.4-py310h5764c6d_1\n",
            "  pycparser          conda-forge/noarch::pycparser-2.21-pyhd8ed1ab_0\n",
            "  pygments           conda-forge/noarch::pygments-2.13.0-pyhd8ed1ab_0\n",
            "  pyopenssl          conda-forge/noarch::pyopenssl-22.1.0-pyhd8ed1ab_0\n",
            "  pyparsing          conda-forge/noarch::pyparsing-3.0.9-pyhd8ed1ab_0\n",
            "  pyqt               conda-forge/linux-64::pyqt-5.15.7-py310h29803b5_2\n",
            "  pyqt5-sip          conda-forge/linux-64::pyqt5-sip-12.11.0-py310hd8f1fbe_2\n",
            "  pyrsistent         conda-forge/linux-64::pyrsistent-0.18.1-py310h5764c6d_2\n",
            "  pysocks            conda-forge/noarch::pysocks-1.7.1-pyha2e5f31_6\n",
            "  python             conda-forge/linux-64::python-3.10.6-h582c2e5_0_cpython\n",
            "  python-dateutil    conda-forge/noarch::python-dateutil-2.8.2-pyhd8ed1ab_0\n",
            "  python-fastjsonsc~ conda-forge/noarch::python-fastjsonschema-2.16.2-pyhd8ed1ab_0\n",
            "  python_abi         conda-forge/linux-64::python_abi-3.10-2_cp310\n",
            "  pytz               conda-forge/noarch::pytz-2022.5-pyhd8ed1ab_0\n",
            "  pyu2f              conda-forge/noarch::pyu2f-0.1.5-pyhd8ed1ab_0\n",
            "  pyzmq              conda-forge/linux-64::pyzmq-24.0.1-py310h330234f_1\n",
            "  qt-main            conda-forge/linux-64::qt-main-5.15.6-hc525480_0\n",
            "  qtconsole          conda-forge/noarch::qtconsole-5.3.2-pyhd8ed1ab_0\n",
            "  qtconsole-base     conda-forge/noarch::qtconsole-base-5.3.2-pyha770c72_0\n",
            "  qtpy               conda-forge/noarch::qtpy-2.2.1-pyhd8ed1ab_0\n",
            "  readline           conda-forge/linux-64::readline-8.1.2-h0f457ee_0\n",
            "  requests           conda-forge/noarch::requests-2.28.1-pyhd8ed1ab_1\n",
            "  rsa                conda-forge/noarch::rsa-4.9-pyhd8ed1ab_0\n",
            "  ruamel_yaml        conda-forge/linux-64::ruamel_yaml-0.15.80-py310h5764c6d_1008\n",
            "  send2trash         conda-forge/noarch::send2trash-1.8.0-pyhd8ed1ab_0\n",
            "  setuptools         conda-forge/noarch::setuptools-65.5.0-pyhd8ed1ab_0\n",
            "  sip                conda-forge/linux-64::sip-6.7.2-py310hd8f1fbe_1\n",
            "  six                conda-forge/noarch::six-1.16.0-pyh6c4a22f_0\n",
            "  soupsieve          conda-forge/noarch::soupsieve-2.3.2.post1-pyhd8ed1ab_0\n",
            "  sqlite             conda-forge/linux-64::sqlite-3.39.4-h4ff8645_0\n",
            "  stack_data         conda-forge/noarch::stack_data-0.5.1-pyhd8ed1ab_0\n",
            "  terminado          conda-forge/noarch::terminado-0.17.0-pyh41d4057_0\n",
            "  tinycss2           conda-forge/noarch::tinycss2-1.2.1-pyhd8ed1ab_0\n",
            "  tk                 conda-forge/linux-64::tk-8.6.12-h27826a3_0\n",
            "  toml               conda-forge/noarch::toml-0.10.2-pyhd8ed1ab_0\n",
            "  toolz              conda-forge/noarch::toolz-0.12.0-pyhd8ed1ab_0\n",
            "  tornado            conda-forge/linux-64::tornado-6.2-py310h5764c6d_1\n",
            "  tqdm               conda-forge/noarch::tqdm-4.64.1-pyhd8ed1ab_0\n",
            "  traitlets          conda-forge/noarch::traitlets-5.5.0-pyhd8ed1ab_0\n",
            "  typing-extensions  conda-forge/noarch::typing-extensions-4.4.0-hd8ed1ab_0\n",
            "  typing_extensions  conda-forge/noarch::typing_extensions-4.4.0-pyha770c72_0\n",
            "  tzdata             conda-forge/noarch::tzdata-2022e-h191b570_0\n",
            "  urllib3            conda-forge/noarch::urllib3-1.26.11-pyhd8ed1ab_0\n",
            "  wcwidth            conda-forge/noarch::wcwidth-0.2.5-pyh9f0ad1d_2\n",
            "  webencodings       conda-forge/noarch::webencodings-0.5.1-py_1\n",
            "  wheel              conda-forge/noarch::wheel-0.37.1-pyhd8ed1ab_0\n",
            "  widgetsnbextension conda-forge/noarch::widgetsnbextension-4.0.3-pyhd8ed1ab_0\n",
            "  xcb-util           conda-forge/linux-64::xcb-util-0.4.0-h166bdaf_0\n",
            "  xcb-util-image     conda-forge/linux-64::xcb-util-image-0.4.0-h166bdaf_0\n",
            "  xcb-util-keysyms   conda-forge/linux-64::xcb-util-keysyms-0.4.0-h166bdaf_0\n",
            "  xcb-util-renderut~ conda-forge/linux-64::xcb-util-renderutil-0.3.9-h166bdaf_0\n",
            "  xcb-util-wm        conda-forge/linux-64::xcb-util-wm-0.4.1-h166bdaf_0\n",
            "  xorg-libxau        conda-forge/linux-64::xorg-libxau-1.0.9-h7f98852_0\n",
            "  xorg-libxdmcp      conda-forge/linux-64::xorg-libxdmcp-1.1.3-h7f98852_0\n",
            "  xz                 conda-forge/linux-64::xz-5.2.6-h166bdaf_0\n",
            "  yaml               conda-forge/linux-64::yaml-0.2.5-h7f98852_2\n",
            "  yarl               conda-forge/linux-64::yarl-1.8.1-py310h5764c6d_0\n",
            "  zeromq             conda-forge/linux-64::zeromq-4.3.4-h9c3ff4c_1\n",
            "  zipp               conda-forge/noarch::zipp-3.10.0-pyhd8ed1ab_0\n",
            "  zstd               conda-forge/linux-64::zstd-1.5.2-h6239696_4\n",
            "\n",
            "\n",
            "Preparing transaction: - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\bdone\n",
            "Executing transaction: | \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\bdone\n",
            "installation finished.\n",
            "WARNING:\n",
            "    You currently have a PYTHONPATH environment variable set. This may cause\n",
            "    unexpected behavior when running the Python interpreter in Colab.\n",
            "    For best results, please verify that your PYTHONPATH only points to\n",
            "    directories of packages that are compatible with the Python interpreter\n",
            "    in Colab: /usr/local\n",
            "Installed kernelspec py310 in /root/.local/share/jupyter/kernels/py310\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python --version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WKEEJJVh2hh4",
        "outputId": "87d365f9-aecc-469e-ff24-bfb3d2e21a61"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.10.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pygame"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JdmrIFLz2MI0",
        "outputId": "6bcf2a8c-ecb0-4747-a064-c89837303a56"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pygame\n",
            "  Using cached pygame-2.1.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (21.9 MB)\n",
            "Installing collected packages: pygame\n",
            "Successfully installed pygame-2.1.2\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "KL_NU-dTxmQ0"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "\n",
        "import gym\n",
        "from gym import spaces\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "\"Arrows Key to play, Ctrl + Z to undo. You can only undo once consecutively.\"\n",
        "\n",
        "\n",
        "class Typical2048Env(gym.Env):\n",
        "    metadata = {\"render_modes\": [\"ai\", \"human\", \"rgb_array\"], \"render_fps\": 20, \"window_size\": 16}\n",
        "\n",
        "    def __init__(self, render_mode=None, size=4, window_size=16):\n",
        "        self._grid = None\n",
        "        self._last_grid = None\n",
        "        self._merged = None\n",
        "        self._epoch = 0\n",
        "\n",
        "        self.size = size  # The size of the square grid\n",
        "        self.ws = window_size\n",
        "        self.window_size = 512 * window_size / 16  # The size of the PyGame window\n",
        "        self.bar_size = 100 * window_size / 16\n",
        "        self.bar = np.array((0, self.bar_size))\n",
        "\n",
        "        self.prob = (.9, .1)  # (.9, .1)\n",
        "        self.action = -1\n",
        "\n",
        "        self.reward_list_length = 1\n",
        "        self.score = 0\n",
        "        self.undo_score = 0\n",
        "        self.reward = 0\n",
        "        self.rewards = [0,]\n",
        "        self.max_score = 0\n",
        "        self.undo_unused = True\n",
        "        self.punishment = -50\n",
        "\n",
        "        self.available_dirs = np.array([True, True, True, True])\n",
        "\n",
        "        # Observations are 16-element lists, storing the numbers at each cell.\n",
        "        # There are 16 possible numbers, ranging from 2**1 to 2**16.\n",
        "        # The id 0 is reserved for EMPTY cell.\n",
        "        self.observation_space = spaces.Box(0, size * size, shape=(size * size,), dtype=int)\n",
        "\n",
        "        # We have 4 actions, corresponding to \"right\", \"down\", \"left\", \"up\" and \"undo\"\n",
        "        self.action_space = spaces.Discrete(4)\n",
        "\n",
        "        \"\"\"\n",
        "        The following dictionary maps abstract actions from `self.action_space` to \n",
        "        the direction we will walk in if that action is taken.\n",
        "        I.e. 0 corresponds to \"right\", 1 to \"down\" etc.\n",
        "        \"\"\"\n",
        "        self._action_to_direction = {\n",
        "            0: np.array([1, 1]),  # right  1st axis\n",
        "            1: np.array([0, 1]),  # down   0th axis\n",
        "            2: np.array([1, -1]),  # left   1st axis\n",
        "            3: np.array([0, -1]),  # up     0th axis\n",
        "        }\n",
        "\n",
        "        assert render_mode is None or render_mode in self.metadata[\"render_modes\"]\n",
        "        self.render_mode = render_mode\n",
        "        self.ai = render_mode == 'ai'\n",
        "        if self.ai:\n",
        "            self.render_mode = 'human'\n",
        "\n",
        "        \"\"\"\n",
        "        If human-rendering is used, `self.window` will be a reference\n",
        "        to the window that we draw to. `self.clock` will be a clock that is used\n",
        "        to ensure that the environment is rendered at the correct framerate in\n",
        "        human-mode. They will remain `None` until human-mode is used for the\n",
        "        first time.\n",
        "        \"\"\"\n",
        "        self.window = None\n",
        "        self.clock = None\n",
        "\n",
        "    def _get_obs(self):\n",
        "        return self._grid\n",
        "\n",
        "    def _get_info(self):\n",
        "        return {\n",
        "            \"highTile\": max(self._grid),\n",
        "            \"score\": self.score,\n",
        "            \"available_dir\": self.available_dirs\n",
        "        }\n",
        "\n",
        "    def reset(self, seed=None, options=None):\n",
        "        # We need the following line to seed self.np_random\n",
        "        super().reset()\n",
        "        # self.np_random.integers\n",
        "        self._epoch += 1\n",
        "\n",
        "        self.max_score = max(self.max_score, self.score)\n",
        "\n",
        "        self.punishment = -50\n",
        "        self.action = -1\n",
        "        self.score = 0\n",
        "        self.reward = 0\n",
        "        self.undo_score = 0\n",
        "        self.rewards = [0,]\n",
        "        self.available_dirs = np.array([True, True, True, True])\n",
        "        self.undo_unused = True\n",
        "        # Spawn the grid with 2 random tiles (2 or 4, i.e. code = 1 or 2)\n",
        "        self._grid = np.random.permutation((0,) * (self.size ** 2 - 2) +\n",
        "                                           tuple(np.random.choice((1, 2), size=(2,), p=self.prob)))\n",
        "        self._last_grid = self._grid.copy()\n",
        "        self._merged = np.zeros((self.size**2,))\n",
        "\n",
        "        observation = self._get_obs()\n",
        "        info = self._get_info()\n",
        "\n",
        "        if self.render_mode == \"human\":\n",
        "            self._render_frame()\n",
        "\n",
        "        return observation, info\n",
        "\n",
        "    def _move_row(self, p: np.ndarray, m: np.ndarray, direction: int, do_reward=False):\n",
        "        \"\"\"\n",
        "        :param p: an ndarray row representing the numbers in a row (or column)\n",
        "        :param m: an ndarray row representing whether the number is JUST merged.\n",
        "        :param direction: an integer signifying whether to slide in the POSITIVE (+1) or NEGATIVE (-1) direction.\n",
        "        :param do_reward: an bool signifying if we update the reward value.\n",
        "        \"\"\"\n",
        "        out = np.zeros_like(p)\n",
        "        mout = np.zeros_like(m)\n",
        "        last = 0\n",
        "        lastidx = 0\n",
        "        direction *= -1\n",
        "        # if direction is -1, i.e., towards the LEFT, then we DON'T need to reverse the array.\n",
        "        # similarly, we NEED to reverse the row if direction is 1.\n",
        "\n",
        "        idx = -1\n",
        "        for i, e in enumerate(p[::direction]):\n",
        "            if e == 0:\n",
        "                continue\n",
        "            if e != last or m[i] != 0 or m[lastidx] != 0:  # either not equal, or one of them is used.\n",
        "                idx += 1\n",
        "                out[idx] = e\n",
        "                mout[idx] = m[i]\n",
        "                last = int(e)\n",
        "            else:\n",
        "                out[idx] = last+1   # merge tiles\n",
        "                mout[idx] = 1\n",
        "                if do_reward:\n",
        "                    self.reward += 2 ** (last + 1)\n",
        "                    self.score += 2 ** (last + 1)\n",
        "                last = 0\n",
        "        m[:] = mout\n",
        "        return not np.all(p-out[::direction] == 0), out[::direction]\n",
        "\n",
        "    def _move_tiles(self, grid: np.ndarray, merge_grid: np.ndarray, action=0, do_reward=False) -> bool:\n",
        "        g = grid.reshape((self.size, self.size))\n",
        "        mg = merge_grid.reshape((self.size, self.size))\n",
        "        # Map the action (element of {0,1,2,3}) to the direction we walk in\n",
        "        direction = self._action_to_direction[action]\n",
        "        # direction[0]: axis.\n",
        "        # direction[1]: +/- value for that axis.\n",
        "        OUT = False\n",
        "        for i in range(self.size):\n",
        "            p = g[:, i] if direction[0] else g[i, :]\n",
        "            m = mg[:, i] if direction[0] else mg[i, :]\n",
        "            out, p[:] = self._move_row(p, m, direction[1], do_reward=do_reward)\n",
        "            if out:\n",
        "                OUT = True\n",
        "                if not do_reward:\n",
        "                    return True\n",
        "\n",
        "        grid[:] = g.reshape((-1,))\n",
        "        return OUT\n",
        "\n",
        "    def is_full(self) -> bool:\n",
        "        ar = [self._move_tiles(self._grid.copy(), self._merged.copy(), action=action) for action in range(4)]\n",
        "        self.available_dirs = np.array(ar)# + [self.undo_unused])\n",
        "        return not (np.any(self.available_dirs))\n",
        "\n",
        "    def _spawn_tile(self):\n",
        "        empty_tiles = self._grid[self._grid == 0]\n",
        "        self._grid[self._grid == 0] = np.random.permutation((0,)*(len(empty_tiles)-1) +\n",
        "                                                            tuple(np.random.choice((1, 2), size=(1,), p=self.prob)))\n",
        "\n",
        "    def step(self, action):\n",
        "        self.reward = 0\n",
        "        self.action = action\n",
        "        if action == 4:\n",
        "            if self.undo_unused:\n",
        "                self._grid[:] = self._last_grid.copy()\n",
        "                self.score = self.undo_score\n",
        "                self.undo_unused = False\n",
        "                self.reward = self.punishment / 10\n",
        "            else:\n",
        "                self.reward = self.punishment\n",
        "                self.punishment -= 50\n",
        "        elif action is not None:\n",
        "            self._last_grid = self._grid.copy()\n",
        "            self.undo_score = self.score\n",
        "            self.undo_unused = True\n",
        "            if not self.is_full():\n",
        "                moved = 0\n",
        "                while self._move_tiles(self._grid, self._merged, action=action, do_reward=True):\n",
        "                    moved = 1\n",
        "                self._merged = np.zeros_like(self._merged)\n",
        "                if moved:\n",
        "                    self._spawn_tile()\n",
        "                else:\n",
        "                    self.reward = 0\n",
        "        # An episode is done iff the agent has reached the target\n",
        "        terminated = self.is_full()\n",
        "        if terminated:\n",
        "            self.reward -= 10\n",
        "        self.rewards += [self.reward]\n",
        "        if len(self.rewards) > self.reward_list_length:\n",
        "            self.rewards = self.rewards[1:]\n",
        "        observation = self._get_obs()\n",
        "        info = self._get_info()\n",
        "\n",
        "        if self.render_mode == \"human\":\n",
        "            self._render_frame()\n",
        "\n",
        "        return observation, self.reward, terminated, False, info\n",
        "\n",
        "    def _get_color(self, tile: int):\n",
        "        colors = (\n",
        "            (237, 228, 218),  # 2,      1\n",
        "            (236, 223, 199),  # 4,      2\n",
        "            (243, 177, 121),  # 8,      3\n",
        "            (245, 149, 99),   # 16,     4\n",
        "            (245, 124, 97),   # 32,     5\n",
        "            (237, 87, 55),    # 64,     6\n",
        "            (236, 206, 113),  # 128,    7\n",
        "            (237, 204, 98),   # 256,    8\n",
        "            (236, 199, 80),   # 512,    9\n",
        "            (236, 197, 64),   # 1024,   10\n",
        "            (236, 197, 1),    # 2048,   11\n",
        "            (94, 220, 151),   # 4096,   12\n",
        "            (236, 77, 88),    # 8192,   13\n",
        "            (37, 186, 99),    # 16384,  14\n",
        "            (0, 124, 189),    # 32768,  15\n",
        "            (0, 0, 0)         # 65536,  16\n",
        "        )\n",
        "        return colors[tile-1]\n",
        "\n",
        "    def render(self):\n",
        "        if self.render_mode == \"rgb_array\":\n",
        "            return self._render_frame()\n",
        "\n",
        "    def _render_frame(self):\n",
        "        pass\n",
        "\n",
        "    def close(self):\n",
        "        pass\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def check(func):\n",
        "        def inner(*args, **kwargs):\n",
        "            if not Output.output:\n",
        "                return\n",
        "            return func(*args, **kwargs)\n",
        "        return inner"
      ],
      "metadata": {
        "id": "hTOF8rS7nqI2"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gc\n",
        "import os\n",
        "import sys\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "from itertools import filterfalse\n",
        "\n",
        "\n",
        "class Output:\n",
        "    has_epsilon = False\n",
        "\n",
        "    def __init__(self, file_input: str, mode: str = 'results', output_every_n=100, random_overlay=False):\n",
        "        \"\"\" mode: either 'results' or 'model'.\n",
        "            ... -o '<path>/<file>.txt'  # outputs experiment data to txt format\n",
        "            ... -o '<path>/<file>.csv'  # outputs experiment data to csv format\n",
        "            ... -o '<path>/<file>.png'  # outputs experiment data chart (provided matplotlib) to png or jpg format\n",
        "            ... -o '<path>/<file>.h5'   # when mode == 'model', outputs neural network model here.\n",
        "            ... -o '<path>'             # when there is no file extension (.xx),\n",
        "                                        # a .txt file, a .csv file and (if mode == 'model')\n",
        "                                            a list of .h5 file checkpoints are stored in this folder.\n",
        "            ... -o None\n",
        "             or -o 'None'               # show plotted chart on screen\n",
        "\n",
        "            # by default, there will be printing onto the console. there is no way to turn it off.\n",
        "            \"\"\"\n",
        "        self.mode = mode\n",
        "        Output.output = (file_input is not None)\n",
        "        if not self.output:\n",
        "            return\n",
        "\n",
        "        file = file_input.rsplit(\".\", 1)\n",
        "        file[0] = \"./\" + file[0]\n",
        "        self.files = {}\n",
        "        self.output_every_n = output_every_n\n",
        "        self.random_overlay = random_overlay\n",
        "        self.df = pd.DataFrame({'episode': [],\n",
        "                                'step': [],\n",
        "                                'score': [], 'epsilon': [], 'good': [], 'best': []})\n",
        "        if file_input.endswith(\".txt\"):\n",
        "            self.files.update({\"txt\": file[0].rsplit('/', 1)[1]})\n",
        "        elif file_input.endswith(\".csv\"):\n",
        "            self.files.update({\"csv\": file[0].rsplit('/', 1)[1]})\n",
        "        elif file_input.endswith(\".png\"):\n",
        "            self.files.update({\"png\": file[0].rsplit('/', 1)[1]})\n",
        "        elif file_input.endswith(\".jpg\"):\n",
        "            self.files.update({\"jpg\": file[0].rsplit('/', 1)[1]})\n",
        "        elif file_input.endswith(\".h5\") and mode == 'model':\n",
        "            self.save_to_single = True\n",
        "            self.files.update({\"h5\": file[0].rsplit('/', 1)[1]})\n",
        "        elif file_input.endswith(\".h5s\") and mode == 'model':\n",
        "            self.save_to_single = False\n",
        "            self.files.update({\"h5\": file[0].rsplit('/', 1)[1]})\n",
        "        else:\n",
        "            file[0] = file[0][2:] if file[0].startswith(\"./\") else file[0]\n",
        "            if \".\" not in file_input: # is a directory\n",
        "                self.files.update({\"txt\": \"data\", \"csv\": \"data\", \"png\": \"evaluation_graph\"})\n",
        "                if mode == 'model':\n",
        "                    self.files.update({\"h5\": \"model\"})\n",
        "                file = [file_input+\"/\"]\n",
        "            else:\n",
        "                print(f\"File format {file[1]} not supported. \"\n",
        "                      f\"Train data and files (if any) is now saved to the directory {file[0]}.\")\n",
        "            try:\n",
        "                os.mkdir(file[0])\n",
        "            except Exception as e:\n",
        "                print(e)\n",
        "        file[0] = file[0][2:] if file[0].startswith(\"./\") else file[0]\n",
        "        file_input = file[0].rsplit(\"/\", 1) if \"/\" in file[0] else (\".\", file[0])\n",
        "        # ignore file format if the format is not supported\n",
        "        self.dir = file_input[0]\n",
        "        print(f\"The following items will be outputted in folder {self.dir}:\\n\"\n",
        "              + '\\n'.join(map(lambda x: '\\t- '+x[1]+'.'+x[0], self.files.items())))\n",
        "\n",
        "        self.actions = {\"txt\": self.output_txt, \"csv\": self.output_csv, \"png\": self.output_img,\n",
        "                        \"jpg\": self.output_img, \"h5\": self.output_model}\n",
        "        self.actions = dict(list(filterfalse(lambda x: x[0] not in self.files, self.actions.items())))\n",
        "\n",
        "        matplotlib.use('Agg')\n",
        "\n",
        "\n",
        "    @check\n",
        "    def output_txt(self, output=\"\", **kwargs):\n",
        "        with open(f\"{self.dir}/{self.files['txt']}.txt\", \"a+\") as f:\n",
        "            f.write(output + \"\\n\")\n",
        "\n",
        "    @check\n",
        "    def output_csv(self, episode=0, step=0, info=None, **kwargs):\n",
        "        self.df.to_csv(f\"{self.dir}/{self.files['csv']}.csv\")\n",
        "\n",
        "    @check\n",
        "    def output_img(self, episode=0, output_every_n=1, do_output=True, **kwargs):\n",
        "        if self.mode != 'model' and episode >= 0 or not do_output:\n",
        "            return\n",
        "        \"\"\"\n",
        "        # there is some issue with plt and pygame.\n",
        "        # plt resizes the pygame window by ignoring Window's screen resize ratio (200% in my display)\n",
        "        # and thus shrinks the window size of pygame after every plt call.\n",
        "        # Currently, I cannot find any resources online that could help me solve this problem, so\n",
        "        # this would NOT be implemented directly. Only the last data.png is saved.\n",
        "        \"\"\"\n",
        "        if episode % output_every_n != output_every_n-1 and episode >= 0:\n",
        "            return\n",
        "        mode = 'png' if 'png' in self.files else 'jpg'\n",
        "\n",
        "        fig, axs = plt.subplots(nrows=3 if self.has_epsilon else 2, ncols=2,\n",
        "                                figsize=(8, 9 if self.has_epsilon else 6), num=1, clear=True)\n",
        "        fig.tight_layout()\n",
        "        self.df = self.df.sort_values(by='episode')\n",
        "        self.df.set_index('episode')\n",
        "        rolling = self.df.rolling(10, on='episode').mean()\n",
        "\n",
        "        # 'best' is used as 'random_score' when self.random_overlay is True.\n",
        "        axs[0, 0].plot(rolling['score'].dropna())\n",
        "        try:\n",
        "            if self.random_overlay:\n",
        "                axs[0, 0].plot(rolling['best'], alpha=.5)\n",
        "                axs[0, 0].legend(['score', 'random'])\n",
        "            else:\n",
        "                axs[0, 0].plot(self.df['good'].dropna())\n",
        "                axs[0, 0].plot(self.df['best'].dropna())\n",
        "                axs[0, 0].legend(['score', 'good', 'best'])\n",
        "        except KeyError:\n",
        "            pass\n",
        "        magicmax = max(5000, (self.df['score'].max()//1000+1) * 1000)\n",
        "        self.df['score'].hist(ax=axs[0, 1], range=[0, magicmax], bins=100)\n",
        "        if self.random_overlay:\n",
        "            self.df['best'].hist(ax=axs[0, 1], range=[0, magicmax], bins=100, alpha=0.5)\n",
        "        axs[0, 1].set_xlabel(\"score\")\n",
        "        axs[0, 1].set_ylabel(\"frequency\")\n",
        "\n",
        "        # 'good' is used as 'random_step' when self.random_overlay is True.\n",
        "        axs[1, 0].plot(rolling['step'].dropna())\n",
        "        if self.random_overlay:\n",
        "            axs[1, 0].plot(rolling['good'], alpha=.5)\n",
        "            axs[1, 0].legend(['step', 'random'])\n",
        "        self.df['step'].hist(ax=axs[1, 1], range=[-5, 2000], bins=100)\n",
        "        if self.random_overlay:\n",
        "            self.df['good'].hist(ax=axs[1, 1], range=[-5, 2000], bins=100, alpha=0.5)\n",
        "        axs[1, 1].set_xlabel(\"step\")\n",
        "        axs[1, 1].set_ylabel(\"frequency\")\n",
        "        if self.has_epsilon:\n",
        "            axs[2, 0].set_ylim([0, 1])\n",
        "            for i in range(15, -1, -1):\n",
        "                self.df[f'epsilon{i}'].plot(ax=axs[2, 0], label=f\"{2**i}\")\n",
        "                self.df[f'epsilon{i}'].hist(ax=axs[2, 1], range=[0, 1], bins=100, label=f\"{2**i}\", alpha=.5)\n",
        "            axs[2, 1].set_xlabel(\"epsilon\")\n",
        "            axs[2, 1].set_ylabel(\"frequency\")\n",
        "            axs[2, 1].legend()\n",
        "        del rolling\n",
        "\n",
        "        plt.savefig(f\"{self.dir}/{self.files[mode]}.{mode}\")\n",
        "        plt.close(fig)\n",
        "        plt.close(\"all\")\n",
        "        gc.collect()\n",
        "\n",
        "    @check\n",
        "    def output_model(self, episode=0, model=None, output_every_n=1, **kwargs):\n",
        "        if episode % output_every_n != output_every_n-1 and episode >= 0:\n",
        "            return\n",
        "        if episode == -1:\n",
        "            filename = f\"{self.dir}/{self.files['h5']}_best.h5\"\n",
        "        elif episode < 0:\n",
        "            filename = f\"{self.dir}/{self.files['h5']}_best_replacedAt{-episode}.h5\"\n",
        "        else:\n",
        "            filename = f\"{self.dir}/{self.files['h5']}_epoch{episode}.h5\"\n",
        "        model.save(filename)\n",
        "\n",
        "    def log(self, done, episode, step, info, model=None, do_output=True, epsilon: list = [-1.], training=False,\n",
        "            best: int = None):\n",
        "        if done:\n",
        "            output = f\"Episode {episode} succeeded in {step} steps with score {info['score']}... epsilon {epsilon} ... training {training}\"\n",
        "        else:\n",
        "            output = f\"Episode {episode} truncated ... in {step} steps with score {info['score']} ... epsilon {epsilon}\"\n",
        "\n",
        "        print(output)\n",
        "\n",
        "        if not self.output:\n",
        "            return\n",
        "        self.has_epsilon = epsilon[0] != -1\n",
        "        entry = {'episode': [episode], 'step': [step],\n",
        "                 'score': [info['score']], 'best': [np.NAN], 'good': [np.NAN]}\n",
        "        entry.update({f'epsilon{i}': eps for i, eps in enumerate(epsilon)})\n",
        "        self.concat(entry)\n",
        "        [a(output=output, episode=episode, step=step, info=info, output_every_n=self.output_every_n,\n",
        "           model=model, do_output=do_output) for a in self.actions.values()]\n",
        "\n",
        "    @check\n",
        "    def logs(self, output: str):\n",
        "        if \"txt\" in self.actions:\n",
        "            self.output_txt(output)\n",
        "\n",
        "    def concat(self, dic: dict):\n",
        "        self.df = pd.concat(\n",
        "            [self.df, pd.DataFrame(dic)],\n",
        "            ignore_index=True\n",
        "        ).groupby('episode').sum(numeric_only=True, min_count=1).reset_index()"
      ],
      "metadata": {
        "id": "2dc6cCDU1jXM"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import collections\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "Experience = collections.namedtuple('Experience',\n",
        "                                    field_names=['state', 'action', 'reward', 'done', 'new_state'])\n",
        "\n",
        "\n",
        "class ExperienceReplay:\n",
        "    \"\"\"\n",
        "    Reference: https://towardsdatascience.com/deep-q-network-dqn-ii-b6bf911b6b2c\n",
        "    There is not much that I could improve the code. @credit: Jordi TORRES.AI\n",
        "    \"\"\"\n",
        "    def __init__(self, capacity, best_capacity=256):\n",
        "        self.buffer = collections.deque(maxlen=capacity)\n",
        "        self.best = []\n",
        "        self.age = 0\n",
        "        self.best_capacity = best_capacity\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.buffer)\n",
        "\n",
        "    def append(self, experience):\n",
        "        self.age += 1\n",
        "        self.buffer.append(experience)\n",
        "        # based on the concept that high reward should be prioritized\n",
        "        # we would make sure that older experiences with high reward values is not dumped\n",
        "        self.best += [(self.age, experience)]\n",
        "        self.best = sorted(self.best, key=lambda x: x[1][2]+x[0]/10000, reverse=True)\n",
        "        if len(self.best) > self.best_capacity:\n",
        "            self.best.pop()\n",
        "        # i.e. reward + age/1000\n",
        "\n",
        "    def sample(self, batch_size):\n",
        "        indices = np.random.choice(len(self.buffer), batch_size,\n",
        "                                   replace=False)\n",
        "        states, actions, rewards, dones, next_states \\\n",
        "            = zip(*([self.buffer[idx] for idx in indices]\n",
        "                    + [x[1] for x in self.best]))\n",
        "\n",
        "        return np.array(states), np.array(actions), \\\n",
        "               np.array(rewards, dtype=np.float32), \\\n",
        "               np.array(dones, dtype=np.uint8), \\\n",
        "               np.array(next_states)"
      ],
      "metadata": {
        "id": "a0NJEBUo1oaM"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gym\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "def choose(env: gym.Env, _q_values: tf.Tensor, available_dirs: np.ndarray) -> np.ndarray:\n",
        "    if env.is_full():\n",
        "        return np.array(-1)\n",
        "    li = (_q_values[0] * available_dirs).numpy()\n",
        "    li[available_dirs*1 == 0] = np.nan\n",
        "    return np.nanargmax(li)\n",
        "\n",
        "\n",
        "num_inps = 4\n",
        "\n",
        "\n",
        "def vectorize(_state: tf.Tensor, available_dirs: np.ndarray, type='normal', normalized=True, expand=True) -> tf.Tensor:\n",
        "    \"\"\" turns the state into a vector before feeding into the neural network.\n",
        "    :param available_dirs: available directions.\n",
        "    :param _state:         input observations, in a shape (16,)\n",
        "    :param type:           either 'normal' (default) or 'one-hot'.\n",
        "                            output shape is (1,16,1) for 'normal', and is (1,16,16=#options) for 'one-hot'.\n",
        "    \"\"\"\n",
        "    if type in ('one-hot', 'one-hot-17'):\n",
        "        options_per_cell = 17 if type == 'one-hot-17' else 16\n",
        "        out = tf.math.multiply(tf.expand_dims(tf.one_hot(_state, options_per_cell), 0),\n",
        "                               available_dirs.reshape((num_inps, 1, 1)))\n",
        "        if expand:\n",
        "            out = tf.expand_dims(out, 0)\n",
        "        if normalized:\n",
        "            out /= options_per_cell\n",
        "        return out\n",
        "    out = tf.math.multiply(tf.expand_dims(_state, 0),\n",
        "                           available_dirs.reshape((num_inps, 1)))\n",
        "    if expand:\n",
        "        out = tf.expand_dims(out, 0)\n",
        "    return out\n",
        "\n",
        "\n",
        "def get_input_type(shape: tuple) -> str:\n",
        "    return 'one-hot' if shape[2] == 16 else \\\n",
        "        'one-hot-17' if shape[2] == 17 else 'normal'"
      ],
      "metadata": {
        "id": "0FIHaE2F1xEn"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test the agent\n",
        "test_episodes = 10000\n",
        "max_steps = 10000"
      ],
      "metadata": {
        "id": "pqJUowSxoRNZ"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "from collections import Counter\n",
        "\n",
        "import gym\n",
        "\n",
        "import sys\n",
        "import os\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "import tensorflow as tf\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Reshape, Conv2D\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "import copy\n",
        "import threading\n",
        "\n",
        "size = 4\n",
        "mode = 'rgb_array'\n",
        "ws   = 16\n",
        "\n",
        "save_interval = 500\n",
        "\n",
        "learning_rate = .00075\n",
        "lr_decay = 1\n",
        "opt = Adam(learning_rate=learning_rate)\n",
        "gamma = .95  # or .95\n",
        "epsilon_decay = 1-5*1e-4  # 1-5*1e-4\n",
        "local_epsilon = [.5]*16\n",
        "\n",
        "# for random agent, use play v1 script with -m human_rand\n",
        "assert mode != \"human_rand\"\n",
        "\n",
        "window_size = 16\n",
        "\n",
        "env = Typical2048Env(render_mode=mode, size=size, window_size=window_size)\n",
        "\n",
        "env.metadata[\"render_fps\"] = 1000000000\n",
        "\n",
        "env.action_space.seed(None)\n",
        "\n",
        "\n",
        "#threading\n",
        "num_threads = 10\n",
        "envs = [copy.deepcopy(env) for i in range(num_threads)]\n",
        "\n",
        "buffer_capacity = 32768\n",
        "best_capacity = 0\n",
        "min_buffer_length = 256\n",
        "buffer = ExperienceReplay(buffer_capacity, best_capacity=best_capacity)\n",
        "\n",
        "ofile = f\"data/qtable_{time.strftime('%Y%m%d%H%M')}\"\n",
        "output = Output(ofile, 'model', output_every_n=save_interval)  # does any output job.\n",
        "folder = output.dir\n",
        "\n",
        "# DQN model\n",
        "num_classes = 4\n",
        "options_per_cell = 16  # 16 if onehot / all models on or before 202212110239\n",
        "train_type = 'one-hot'  #'one-hot' if output 16\n",
        "input_shape = (num_classes, size ** 2, options_per_cell)\n",
        "epsilon_min = 0\n",
        "epsilon = .5\n",
        "\n",
        "file = None\n",
        "input_file = None\n",
        "\n",
        "if file is not None:\n",
        "    model = tf.keras.models.load_model(file, compile=False)\n",
        "    print(model.summary())\n",
        "    train_type = get_input_type(model.shape)\n",
        "else:\n",
        "    \"Dimensionality reduction by obtaining Q-value rows by using a neural network.\"\n",
        "    model = Sequential(\n",
        "        [\n",
        "            tf.keras.Input(shape=input_shape),\n",
        "            Reshape((num_classes, size, size, options_per_cell)),\n",
        "            Conv2D(128, kernel_size=(2, 2), activation=\"relu\", padding='SAME'),\n",
        "            Conv2D(32, kernel_size=(2, 2), activation=\"relu\", padding='SAME'),\n",
        "            Reshape((-1,)),\n",
        "            Dense(128, activation='relu'),\n",
        "            Dense(num_classes)\n",
        "        ]\n",
        "    )\n",
        "    model.build()\n",
        "\n",
        "\n",
        "print(model.summary())\n",
        "with open(f\"{folder}/model_structure.txt\", \"a+\") as f:\n",
        "    model.summary(print_fn=lambda x: f.write(x + \"\\n\"))\n",
        "\n",
        "with open(f\"{folder}/model_structure.txt\", \"a+\") as f:\n",
        "    f.write(f\"Model trained from loaded file: {input_file}\\n\")\n",
        "    f.write(f\"Parameters: \\tbuffer size: {buffer_capacity}\\n\")\n",
        "    f.write(f\"\\t\\t\\t\\t* best capacity: {best_capacity}\\n\")\n",
        "    f.write(f\"\\t\\t\\t\\t* gamma: {gamma}, epsilon: {epsilon} (decay = {epsilon_decay}, min = {epsilon_min})\\n\")\n",
        "    f.write(f\"\\t\\t\\t\\t* lr: {learning_rate} (decay = {lr_decay})\\n\")\n",
        "    model.summary(print_fn=lambda x: f.write(x + \"\\n\"))\n",
        "\n",
        "\n",
        "def end():\n",
        "    if episode > 0:\n",
        "        print(f\"Average score: {total_score / episode:.2f}\\n\" +\n",
        "              f\"Maximum score: {max_score:d}\\n\" + f\"Highest tile: {2 ** high_tile:d}\\n\" +\n",
        "              f\"Average steps: {total_steps / episode:.2f} ([{min_steps_achieved} to {max_steps_achieved}])\")\n",
        "\n",
        "    env.close()\n",
        "\n",
        "episode = 0\n",
        "total_score = 0\n",
        "max_score = 0\n",
        "high_tile = 0\n",
        "total_steps = 0\n",
        "min_steps_achieved = (2 << 15)\n",
        "max_steps_achieved = 0\n",
        "\n",
        "len_top_tiles = 10  # maximum number of games that we are keeping track of (the high score)\n",
        "\n",
        "running = True\n",
        "step = 0\n",
        "\n",
        "top_tiles = []\n",
        "\n",
        "# threading\n",
        "class PlayModel (threading.Thread):\n",
        "    def __init__(self, env, episode):\n",
        "        threading.Thread.__init__(self)\n",
        "        self.env = env\n",
        "        self.episode = episode\n",
        "    def run(self):\n",
        "        global max_score, high_tile, total_score, top_tiles, epsilon, \\\n",
        "            max_steps_achieved, min_steps_achieved, total_steps, output\n",
        "        env = self.env\n",
        "        episode = self.episode\n",
        "\n",
        "        info = {'available_dir': np.array([True, True, True, True]), 'score': 0, 'highTile': 0}\n",
        "\n",
        "        \n",
        "        state = env.reset(seed=None)[0]  # [0] for observation only\n",
        "        state = vectorize(state, info['available_dir'], type=train_type)\n",
        "        total_testing_rewards = 0\n",
        "\n",
        "        for step in range(max_steps):\n",
        "            \"Obtain Q-values from network.\"\n",
        "            q_values = model(state)\n",
        "\n",
        "            \"Select action using epsilon-greedy strategy.\"\n",
        "            sample_epsilon = np.random.rand()\n",
        "            thisgame_hi = info['highTile']\n",
        "            self_epsilon = local_epsilon[thisgame_hi]\n",
        "            if sample_epsilon <= self_epsilon:\n",
        "                action = env.action_space.sample(mask=info['available_dir'].astype(np.int8))\n",
        "            else:\n",
        "                action = choose(env, q_values, info['available_dir'])\n",
        "            \"Obtain q-value for the selected action.\"\n",
        "            q_value = q_values[0, action]\n",
        "\n",
        "            \"Deterimine next state.\"\n",
        "            new_state, reward, done, truncated, info = env.step(action)  # take action and get reward\n",
        "            new_state = vectorize(new_state, info['available_dir'], type=train_type)\n",
        "            buffer.append(Experience(state, action, reward, done, new_state))\n",
        "\n",
        "            state = new_state\n",
        "\n",
        "            \"From the Q-learning update formula, we have:\"\n",
        "            \"   Q'(S, A) = Q(S, A) + a * {R + λ argmax[a, Q(S', a)] - Q(S, A)}\"\n",
        "            \"Target of Q' is given by: \"\n",
        "            \"   R + λ argmax[a, Q(S', a)]\"\n",
        "            \"Hence, MSE loss function is given by: \"\n",
        "            \"   L(w) = E[(R + λ argmax[a, Q(S', a, w)] - Q(S, a, w))**2]\"\n",
        "            next_q_values = model(new_state)\n",
        "            next_action = choose(env, next_q_values, info['available_dir'])\n",
        "            next_q_value = next_q_values[0, next_action]\n",
        "\n",
        "            observed_q_value = reward + (gamma * next_q_value)\n",
        "            loss = (observed_q_value - q_value) ** 2\n",
        "\n",
        "            def decay(ep: float) -> float:\n",
        "                ep *= epsilon_decay\n",
        "                return max(ep, epsilon_min)\n",
        "\n",
        "            self_epsilon = decay(self_epsilon)\n",
        "            epsilon = decay(epsilon)\n",
        "            for i in range(thisgame_hi+1):\n",
        "                local_epsilon[i] = min(decay(local_epsilon[i]), decay(local_epsilon[thisgame_hi]))\n",
        "\n",
        "            # print(state, action)\n",
        "            if done or truncated:\n",
        "                total_score += info['score']\n",
        "                max_score = max(max_score, info['score'])\n",
        "                high_tile = max(high_tile, info['highTile'])\n",
        "                top_tiles += [2 ** info['highTile']]\n",
        "                if len(top_tiles) > len_top_tiles:\n",
        "                    del top_tiles[0]\n",
        "\n",
        "                soutput = f\"Episode {episode} succeeded in {step} steps with score {info['score']},\" \\\n",
        "                          f\" high tile {2 ** info['highTile']}..., \\n\" \\\n",
        "                          f\"Highest tile frequencies: {top_tiles}\" \\\n",
        "                          f\"\\nepsilon: {self_epsilon}; q_values: {q_values}\"\n",
        "                print(soutput)\n",
        "\n",
        "                with open(f\"{folder}/_descriptions.txt\", \"a+\") as f:\n",
        "                    f.write(soutput + \"\\n\")\n",
        "                with open(f\"{folder}/_data.txt\", \"a+\") as f:\n",
        "                    f.write(f\"{episode}\\t{step}\\t{info['score']}\\t{info['highTile']}\\n\")\n",
        "\n",
        "                output.log(done, episode, step, info, model=model, do_output=False, epsilon=local_epsilon)\n",
        "\n",
        "                total_steps += step\n",
        "                max_steps_achieved = max(max_steps_achieved, step)\n",
        "                min_steps_achieved = min(min_steps_achieved, step)\n",
        "                break\n",
        "    def join(self):\n",
        "        threading.Thread.join(self)\n",
        "\n",
        "class TrainModel (threading.Thread):\n",
        "\n",
        "    def __init__(self, experience, episode):\n",
        "        threading.Thread.__init__(self)\n",
        "        self.experience = experience\n",
        "        self.episode = episode\n",
        "\n",
        "    @staticmethod\n",
        "    def squeeze(inp: np.ndarray):\n",
        "        return np.squeeze(inp, axis=1)\n",
        "\n",
        "    def run(self):\n",
        "        global max_score, total_score, epsilon, \\\n",
        "            max_steps_achieved, min_steps_achieved, total_steps, output, high\n",
        "        experience = self.experience\n",
        "        episode = self.episode\n",
        "        state, action, reward, done, new_state = experience\n",
        "\n",
        "        with tf.GradientTape() as tape:  # tracing and computing the gradients ourselves.\n",
        "            \"Obtain Q-values from network.\"\n",
        "            q_values = model(self.squeeze(state))\n",
        "\n",
        "            \"Obtain q-value for the selected action.\"\n",
        "            q_value = tf.gather(q_values, tf.constant(action), axis=1)#q_values[action]\n",
        "            #print(q_values)\n",
        "\n",
        "            \"From the Q-learning update formula, we have:\"\n",
        "            \"   Q'(S, A) = Q(S, A) + a * {R + λ argmax[a, Q(S', a)] - Q(S, A)}\"\n",
        "            \"Target of Q' is given by: \"\n",
        "            \"   R + λ argmax[a, Q(S', a)]\"\n",
        "            \"Hence, MSE loss function is given by: \"\n",
        "            \"   L(w) = E[(R + λ argmax[a, Q(S', a, w)] - Q(S, a, w))**2]\"\n",
        "            next_q_values = tf.stop_gradient(model(self.squeeze(new_state)))\n",
        "            next_actions = tf.math.argmax(next_q_values, 1)\n",
        "            next_q_value = tf.gather(next_q_values, next_actions, axis=1)\n",
        "\n",
        "            observed_q_value = reward + (gamma * next_q_value)\n",
        "            loss = (observed_q_value - q_value) ** 2\n",
        "\n",
        "            \"Computing and applying gradients\"\n",
        "            grads = tape.gradient(loss, model.trainable_variables)\n",
        "            opt.apply_gradients(zip(grads, model.trainable_variables))\n",
        "\n",
        "    def join(self):\n",
        "        threading.Thread.join(self)\n",
        "\n",
        "save_interval = 50\n",
        "train_episode = 0\n",
        "\n",
        "print(\"Training started ...\")\n",
        "trainThreads = []\n",
        "for episode in range(test_episodes):\n",
        "    thread = PlayModel(envs[episode % num_threads], episode)\n",
        "    thread.start()\n",
        "    trainThreads.append(thread)\n",
        "    if episode % num_threads == num_threads-1:\n",
        "        [trainThread.join() for trainThread in trainThreads]\n",
        "        trainThreads = []\n",
        "    if episode % save_interval > save_interval - 5:\n",
        "        output.concat({'episode': [episode], 'best': [np.NAN], 'good': [np.NAN]})\n",
        "        output.output_img(episode=-1)\n",
        "\n",
        "    if len(buffer) > min_buffer_length:\n",
        "        for j in range(num_threads):\n",
        "            thread = TrainModel(buffer.sample(512), train_episode)\n",
        "            thread.start()\n",
        "            trainThreads.append(thread)\n",
        "            if j == num_threads - 1:\n",
        "                [trainThread.join() for trainThread in trainThreads]\n",
        "                trainThreads = []\n",
        "            if train_episode % save_interval > save_interval - 5:\n",
        "                output.concat({'episode': [episode], 'best': [np.NAN], 'good': [np.NAN]})\n",
        "                output.output_img(episode=-1)\n",
        "            train_episode += 1\n",
        "\n",
        "\n",
        "end()\n"
      ],
      "metadata": {
        "id": "4Wf0x5YGxrEs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b78c485-0707-4fe2-daf3-83008c62a8c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Errno 17] File exists: 'data/qtable_202301101231/'\n",
            "The following items will be outputted in folder data/qtable_202301101231:\n",
            "\t- data.txt\n",
            "\t- data.csv\n",
            "\t- evaluation_graph.png\n",
            "\t- model.h5\n",
            "Model: \"sequential_16\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " reshape_32 (Reshape)        (None, 4, 4, 4, 16)       0         \n",
            "                                                                 \n",
            " conv2d_32 (Conv2D)          (None, 4, 4, 4, 128)      8320      \n",
            "                                                                 \n",
            " conv2d_33 (Conv2D)          (None, 4, 4, 4, 32)       16416     \n",
            "                                                                 \n",
            " reshape_33 (Reshape)        (None, 2048)              0         \n",
            "                                                                 \n",
            " dense_32 (Dense)            (None, 128)               262272    \n",
            "                                                                 \n",
            " dense_33 (Dense)            (None, 4)                 516       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 287,524\n",
            "Trainable params: 287,524\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Training started ...\n",
            "Episode 5 succeeded in 76 steps with score 556, high tile 64..., \n",
            "Highest tile frequencies: [64]\n",
            "epsilon: 0.4467861033280897; q_values: [[-0.00060849 -0.00418481 -0.0018351   0.0006895 ]]\n",
            "Episode 5 succeeded in 76 steps with score 556... epsilon [0.3425828639261568, 0.34430049819652575, 0.3456808040654127, 0.35425675424176967, 0.37001103271023345, 0.3948670313551932, 0.44544741934944665, 0.49900074975003134, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5] ... training False\n",
            "Episode 6 succeeded in 78 steps with score 572, high tile 64..., \n",
            "Highest tile frequencies: [64, 64]\n",
            "epsilon: 0.4381560333303315; q_values: [[-0.00088401  0.00035931 -0.00435945 -0.00036359]]\n",
            "Episode 6 succeeded in 78 steps with score 572... epsilon [0.33546187552626106, 0.33714380674489414, 0.3384954213302533, 0.34689311027946046, 0.36231991751093084, 0.38665925494292125, 0.4364064732240676, 0.4965113522812504, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5] ... training False\n",
            "Episode 1 succeeded in 82 steps with score 608, high tile 64..., \n",
            "Highest tile frequencies: [64, 64, 64]\n",
            "epsilon: 0.4357521907645357; q_values: [[ 0.00102161 -0.00288489 -0.00225587 -0.00171902]]\n",
            "Episode 1 succeeded in 82 steps with score 608... epsilon [0.3339553127235635, 0.33562969037144674, 0.3369752348415217, 0.3453352096815483, 0.3606927349598822, 0.38492276417209403, 0.43444656717398555, 0.49626309660510975, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5] ... training False\n",
            "Episode 7 succeeded in 94 steps with score 676, high tile 64..., \n",
            "Highest tile frequencies: [64, 64, 64, 64]\n",
            "epsilon: 0.4147024739336952; q_values: [[ 0.00186482 -0.00340956 -0.00466982  0.0030038 ]]\n",
            "Episode 7 succeeded in 94 steps with score 676... epsilon [0.3181411208954846, 0.31973620970349187, 0.3210180369708387, 0.3289821317611667, 0.3436124134787514, 0.36669504866738306, 0.41387369083221354, 0.486190778918382, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5] ... training False\n",
            "Episode 3 succeeded in 105 steps with score 776, high tile 64..., \n",
            "Highest tile frequencies: [64, 64, 64, 64, 64]\n",
            "epsilon: 0.40043544997188846; q_values: [[-0.00091857 -0.00071079 -0.00137717  0.0012545 ]]\n",
            "Episode 0 succeeded in 107 steps with score 1012, high tile 128..., \n",
            "Highest tile frequencies: [64, 64, 64, 64, 64, 128]\n",
            "epsilon: 0.4744209316359147; q_values: [[-0.00113183 -0.00341499 -0.00171174  0.00156481]]\n",
            "Episode 3 succeeded in 105 steps with score 776... epsilon [0.3075035272483282, 0.3090452815281772, 0.3102842487038844, 0.31798205033503685, 0.3321231435081887, 0.35443397122738335, 0.4000351146307791, 0.47370965599485704, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5] ... training False\n",
            "Episode 0 succeeded in 107 steps with score 1012... epsilon [0.3075035272483282, 0.3090452815281772, 0.3102842487038844, 0.31798205033503685, 0.3321231435081887, 0.35443397122738335, 0.4000351146307791, 0.47370965599485704, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5] ... training False\n",
            "Episode 4 succeeded in 118 steps with score 1164, high tile 128..., \n",
            "Highest tile frequencies: [64, 64, 64, 64, 64, 128, 128]\n",
            "epsilon: 0.4640950902955516; q_values: [[ 0.00420642 -0.00558526 -0.00281085  0.00108111]]\n",
            "Episode 4 succeeded in 118 steps with score 1164... epsilon [0.300810667759563, 0.302318865530797, 0.30353086640373556, 0.311061124250429, 0.324894434451228, 0.3467196637243207, 0.39132829153592164, 0.4633992956734142, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5] ... training False\n",
            "Episode 9 succeeded in 129 steps with score 1252, high tile 128..., \n",
            "Highest tile frequencies: [64, 64, 64, 64, 64, 128, 128, 128]\n",
            "epsilon: 0.45444832712541394; q_values: [[-0.00109099 -0.00080631 -0.00240672  0.0019411 ]]\n",
            "Episode 9 succeeded in 129 steps with score 1252... epsilon [0.2947053163240886, 0.29618290322139257, 0.29737030492926664, 0.30474772620637886, 0.31830027103100006, 0.3396825283315079, 0.38338576488197906, 0.45399399241037036, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5] ... training False\n",
            "Episode 8 succeeded in 143 steps with score 1464, high tile 128..., \n",
            "Highest tile frequencies: [64, 64, 64, 64, 64, 128, 128, 128, 128]\n",
            "epsilon: 0.4470096081321558; q_values: [[-0.00230716  0.00059865 -0.00267492  0.00433377]]\n",
            "Episode 8 succeeded in 143 steps with score 1464... epsilon [0.2900263926653314, 0.29148052048026163, 0.29264907026509374, 0.2999093630445437, 0.31324673929532576, 0.3342895186698536, 0.37729889563879154, 0.4467861033280897, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5] ... training False\n",
            "Episode 2 succeeded in 150 steps with score 1504, high tile 128..., \n",
            "Highest tile frequencies: [64, 64, 64, 64, 64, 128, 128, 128, 128, 128]\n",
            "epsilon: 0.4461162592068269; q_values: [[-0.00020367 -0.00141941 -0.00111883  0.00447263]]\n",
            "Episode 2 succeeded in 150 steps with score 1504... epsilon [0.28959157055987467, 0.29104351827349656, 0.2922103161099177, 0.29945972389451053, 0.31277710408228143, 0.33378833506720174, 0.3767332302223428, 0.4461162592068269, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5] ... training False\n",
            "Episode 10 succeeded in 119 steps with score 1096, high tile 128..., \n",
            "Highest tile frequencies: [64, 64, 64, 64, 128, 128, 128, 128, 128, 128]\n",
            "epsilon: 0.43903344188342464; q_values: [[3.840909  2.533045  2.636198  3.5333498]]\n",
            "Episode 10 succeeded in 119 steps with score 1096... epsilon [0.272722978138752, 0.2742274642145886, 0.27546457852696293, 0.2831469231586548, 0.29618290322139257, 0.31845950078139074, 0.3628639413203132, 0.43903344188342464, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5] ... training False\n",
            "Episode 11 succeeded in 133 steps with score 1280, high tile 128..., \n",
            "Highest tile frequencies: [64, 64, 64, 128, 128, 128, 128, 128, 128, 128]\n",
            "epsilon: 0.42947781446123307; q_values: [[17.273687  12.00065   12.310101  15.7512455]]\n",
            "Episode 11 succeeded in 133 steps with score 1280... epsilon [0.255044946986438, 0.25658020167116113, 0.25773770440586496, 0.26612082124418096, 0.2787909031416618, 0.3006602624256832, 0.35125758650116234, 0.42947781446123307, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5] ... training False\n",
            "Episode 12 succeeded in 118 steps with score 1088, high tile 128..., \n",
            "Highest tile frequencies: [64, 64, 128, 128, 128, 128, 128, 128, 128, 128]\n",
            "epsilon: 0.42562889793277126; q_values: [[56.010796 40.551243 41.356358 51.002956]]\n",
            "Episode 12 succeeded in 118 steps with score 1088... epsilon [0.24030883590099877, 0.24187632405531856, 0.24296749361840494, 0.2517500024257338, 0.2650581989432712, 0.2885795191523308, 0.34121492815391796, 0.42562889793277126, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5] ... training False\n",
            "Episode 13 succeeded in 187 steps with score 2296, high tile 256..., \n",
            "Highest tile frequencies: [64, 128, 128, 128, 128, 128, 128, 128, 128, 256]\n",
            "epsilon: 0.4908327664321144; q_values: [[129.93675  96.9763   98.46491 118.90134]]\n",
            "Episode 13 succeeded in 187 steps with score 2296... epsilon [0.21874384867980487, 0.22028081299125743, 0.2212745593589797, 0.22984698011165255, 0.24248192296094007, 0.26479320700887765, 0.3163957126158684, 0.4030474131235856, 0.4908327664321144, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5] ... training False\n",
            "Episode 14 succeeded in 93 steps with score 688, high tile 64..., \n",
            "Highest tile frequencies: [128, 128, 128, 128, 128, 128, 128, 128, 256, 64]\n",
            "epsilon: 0.3134034410158337; q_values: [[359.06873 316.39578 319.68488 361.32217]]\n",
            "Episode 14 succeeded in 93 steps with score 688... epsilon [0.20869829628871192, 0.21026981223911048, 0.21142977318864795, 0.22006058724846944, 0.23413980874017504, 0.2569654571649363, 0.3134034410158337, 0.4030474131235856, 0.4908327664321144, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5] ... training False\n",
            "Episode 15 succeeded in 80 steps with score 616, high tile 64..., \n",
            "Highest tile frequencies: [128, 128, 128, 128, 128, 128, 128, 256, 64, 64]\n",
            "epsilon: 0.30673553680474225; q_values: [[523.45917 647.03766 671.45087 575.07086]]\n",
            "Episode 15 succeeded in 80 steps with score 616... epsilon [0.20041285667686856, 0.202022994058169, 0.203239080680211, 0.21174723525757624, 0.22653742372624933, 0.2501185275461914, 0.30673553680474225, 0.4030474131235856, 0.4908327664321144, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5] ... training False\n",
            "Episode 16 succeeded in 80 steps with score 592, high tile 64..., \n",
            "Highest tile frequencies: [128, 128, 128, 128, 128, 128, 256, 64, 64, 64]\n",
            "epsilon: 0.3017146811268932; q_values: [[1058.2463 1166.3562 1122.0541 1088.6954]]\n",
            "Episode 16 succeeded in 80 steps with score 592... epsilon [0.1924563536724737, 0.1940996175038942, 0.1954634235572784, 0.20395184227283716, 0.21951098565680946, 0.24248192296094007, 0.3017146811268932, 0.4030474131235856, 0.4908327664321144, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5] ... training False\n"
          ]
        }
      ]
    }
  ]
}